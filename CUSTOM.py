# -*- coding: utf-8 -*-
"""CUSTOM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QilfzZ0InTI3kG5_a5VkXqo06CDjLZt5
"""

## We will be writing Unet Architecture from Scratch for 3d data.

#importing utilities
import numpy as np
import tensorflow as tf
import keras
import gzip
from tensorflow.keras.layers import add, Input, Concatenate, concatenate, BatchNormalization, Conv3D, Conv3DTranspose, MaxPooling3D, Dropout, Cropping3D, UpSampling3D, Conv2D, ReLU, UpSampling2D, GlobalAveragePooling2D, Multiply, Activation, Add, GlobalAveragePooling3D, AveragePooling3D, Flatten, Dense
from tensorflow.keras.models import Model
from tensorflow.keras import backend as K
from tensorflow.keras.utils import to_categorical, plot_model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.metrics import MeanIoU
from tensorflow.keras.initializers import he_uniform
import SimpleITK as sitk

K.set_image_data_format('channels_last')
# K.set_learning_phase(1)



kernel_initializer =  'he_uniform' #Try others if you want


################################################################
def simple_unet_model(IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH, IMG_CHANNELS, num_classes):
#Build the model
    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH, IMG_CHANNELS))
    #s = Lambda(lambda x: x / 255)(inputs)   #No need for this if we normalize our inputs beforehand
    s = inputs

    #Contraction path
    c1 = Conv3D(16, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(s)
    c1 = Dropout(0.1)(c1)
    c1 = Conv3D(16, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c1)
    p1 = MaxPooling3D((2, 2, 2))(c1)
    
    c2 = Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(p1)
    c2 = Dropout(0.1)(c2)
    c2 = Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c2)
    p2 = MaxPooling3D((2, 2, 2))(c2)
     
    c3 = Conv3D(64, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(p2)
    c3 = Dropout(0.2)(c3)
    c3 = Conv3D(64, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c3)
    p3 = MaxPooling3D((2, 2, 2))(c3)
     
    c4 = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(p3)
    c4 = Dropout(0.2)(c4)
    c4 = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c4)
    p4 = MaxPooling3D(pool_size=(2, 2, 2))(c4)
     
    c5 = Conv3D(256, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(p4)
    c5 = Dropout(0.3)(c5)
    c5 = Conv3D(256, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c5)
    
    #Expansive path 
    u6 = Conv3DTranspose(128, (2, 2, 2), strides=(2, 2, 2), padding='same')(c5)
    u6 = concatenate([u6, c4])
    c6 = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(u6)
    c6 = Dropout(0.2)(c6)
    c6 = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c6)
     
    u7 = Conv3DTranspose(64, (2, 2, 2), strides=(2, 2, 2), padding='same')(c6)
    u7 = concatenate([u7, c3])
    c7 = Conv3D(64, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(u7)
    c7 = Dropout(0.2)(c7)
    c7 = Conv3D(64, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c7)
     
    u8 = Conv3DTranspose(32, (2, 2, 2), strides=(2, 2, 2), padding='same')(c7)
    u8 = concatenate([u8, c2])
    c8 = Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(u8)
    c8 = Dropout(0.1)(c8)
    c8 = Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c8)
     
    u9 = Conv3DTranspose(16, (2, 2, 2), strides=(2, 2, 2), padding='same')(c8)
    u9 = concatenate([u9, c1])
    c9 = Conv3D(16, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(u9)
    c9 = Dropout(0.1)(c9)
    c9 = Conv3D(16, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c9)
     
    outputs = Conv3D(num_classes, (1, 1, 1), activation='softmax')(c9)
     
    model = Model(inputs=[inputs], outputs=[outputs])
    #compile model outside of this function to make it flexible. 
    model.summary()
    
    return model



# https://towardsdatascience.com/review-3d-u-net-volumetric-segmentation-medical-image-segmentation-8b592560fac1
#chnages to UNEt as per above link



class UnetArchitecture_:
    def __init__(self, input_layer):
        self.concate_layers = []
        self.input_layer = input_layer
        self.filters = [16, 32, 64, 128]
        self.initializer= he_uniform(seed=1)
        # self.regularizer = tensorflow.keras.regularizers.l2()
    
    def conv_relu(self, X, filters=64):
        X = Conv3D(filters, kernel_size=(3,3,3), padding='same', activation='relu', kernel_initializer= self.initializer)(X)
        # X = BatchNormalization()(X)
        X = Dropout(0.1)(X)
        X = Conv3D(filters, kernel_size=(3,3,3), padding='same', activation='relu', kernel_initializer= self.initializer)(X)
        X = BatchNormalization()(X)
        self.concate_layers.append(X)
        return X
      
    def up_conv_relu(self, X, filters=64):
        X = Conv3D(filters, kernel_size=(3,3,3), padding='same', activation='relu', kernel_initializer= self.initializer)(X)
        # X = BatchNormalization()(X)
        X= Dropout(0.1)(X)
        X = Conv3D(filters, kernel_size=(3,3,3), padding='same', activation='relu', kernel_initializer= self.initializer)(X)
        X = BatchNormalization()(X)
        return X
    
    def model(self):
        X = self.input_layer
        for index in range(4):
            X = self.conv_relu(X, self.filters[index])
            X = MaxPooling3D()(X)

        
        X = Conv3D(256, kernel_size=(3,3,3), padding='same', activation='relu', kernel_initializer= self.initializer)(X)
        X = BatchNormalization()(X)
        X = Dropout(0.1)(X)

        for i in range(-1, -5, -1):
            X = UpSampling3D()(X)
            X = Conv3D(self.filters[i], (2,2,2), padding='same')(X)
            X = concatenate([self.concate_layers[i], X], axis=-1)
            # print(i, X.shape, self.filters[i])
            X = self.up_conv_relu(X, self.filters[i])

        output_layer = Conv3D(4, (1, 1, 1), activation='softmax')(X)
    
        model = Model(self.input_layer, output_layer)
        return model

    def __call__(self):
        return self.model()     


# X = Input(shape=(128,128,128,3))
# unet_model = UnetArchitecture(X)()
# unet_model.summary()


def load_img(image_dir, image_list):
  images= []
  for num, i in enumerate(image_list):
    if str(i).endswith(".npy.gz"):
      image = gzip.GzipFile(image_dir+i, 'r')
      images.append(np.load(image))

    else:
        image = sitk.ReadImage(i)[:,:,:,0]
        image = sitk.GetArrayFromImage(image)
        images.append(image)
  return images

def ImageDataLoader(image_dir, image_list, mask_dir, mask_list, batch_size=1):

    L = len(image_list)

    #keras needs the generator infinite, so we will use while true  
    while True:

        batch_start = 0
        batch_end = batch_size

        while batch_start < L:
            limit = min(batch_end, L)
                       
            X = load_img(image_dir, image_list[batch_start:limit])
            Y = load_img(mask_dir, mask_list[batch_start:limit])

            yield (X,Y) #a tuple with two numpy arrays with batch_size samples     

            batch_start += batch_size   
            batch_end   += batch_size

# object_ = PlayWithImage()
# object_.load_img('nnc', 'jjs')



####################################################################################
# V-Net
####################################################################################


def conv_block(input_mat,num_filters,kernel_size,batch_norm):
  X = Conv3D(num_filters,kernel_size=(kernel_size,kernel_size,kernel_size),strides=(1,1,1),padding='same')(input_mat)
  if batch_norm:
    X = BatchNormalization()(X)
  
  X = Activation('relu')(X)
  
  X = Conv3D(num_filters,kernel_size=(kernel_size,kernel_size,kernel_size),strides=(1,1,1),padding='same')(X)
  if batch_norm:
    X = BatchNormalization()(X)
  
  X = Activation('relu')(X)
  
  X = Add()([input_mat,X]);
  
  return X


def Vnet_3d(IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH, IMG_CHANNELS, n_filters = 8, dropout = 0.2, batch_norm = True):

  inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH, IMG_CHANNELS))
  s = inputs
  c1 = Conv3D(n_filters,kernel_size = (5,5,5) , strides = (1,1,1) , padding='same')(s)
  
  c2 = Conv3D(n_filters*2,kernel_size = (3,3,3) , strides = (2,2,2) , padding = 'same' )(c1)
  
  c3 = conv_block(c2 , n_filters*2,5,True)
  
  p3 = Conv3D(n_filters*4,kernel_size = (3,3,3) , strides = (2,2,2), padding = 'same')(c3)
  p3 = Dropout(dropout)(p3)
  
  c4 = conv_block(p3, n_filters*4,5,True)
  p4 = Conv3D(n_filters*8,kernel_size = (3,3,3) , strides = (2,2,2) , padding='same')(c4)
  p4 = Dropout(dropout)(p4)
  
  c5 = conv_block(p4, n_filters*8,5,True)
  p6 = Conv3D(n_filters*16,kernel_size = (3,3,3) , strides = (2,2,2) , padding='same')(c5)
  p6 = Dropout(dropout)(p6)
  #c6 = conv_block(p5, n_filters*8,5,True)
  #p6 = Conv3D(n_filters*16,kernel_size = (2,2,2) , strides = (2,2,2) , padding='same')(c6)

  p7 = conv_block(p6,n_filters*16,5,True)
    
  u6 = Conv3DTranspose(n_filters*8, (3,3,3), strides=(2, 2, 2), padding='same')(p7);
  u6 = concatenate([u6,c5]);
  c7 = conv_block(u6,n_filters*16,5,True)
  c7 = Dropout(dropout)(c7)
  u7 = Conv3DTranspose(n_filters*4,(3,3,3),strides = (2,2,2) , padding= 'same')(c7);

  
  u8 = concatenate([u7,c4]);
  c8 = conv_block(u8,n_filters*8,5,True)
  c8 = Dropout(dropout)(c8)
  u9 = Conv3DTranspose(n_filters*2,(3, 3,3),strides = (2,2,2) , padding= 'same')(c8);
  
  u9 = concatenate([u9,c3])
  c9 = conv_block(u9,n_filters*4,5,True)
  c9 = Dropout(dropout)(c9)
  u10 = Conv3DTranspose(n_filters,(3,3,3),strides = (2,2,2) , padding= 'same')(c9)
  
  
  u10 = concatenate([u10,c1]);
  c10 = Conv3D(n_filters*2,kernel_size = (5,5,5),strides = (1,1,1) , padding = 'same')(u10)
  c10 = Dropout(dropout)(c10)
  c10 = Add()([c10,u10])
  
  #c9 = conv_block(u9,n_filters,3,batch_norm)
  outputs = Conv3D(4, (1,1,1), activation='softmax')(c10)

  model = Model(inputs=[s], outputs=[outputs])

  return model




def SurvPredNet(input_img,age_m):
    kernel_initializer =  'he_uniform'
    #input_img = BatchNormalization()(input_img)
    #Contraction path
    c1 = Conv3D(16, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(input_img)
    c1 = Dropout(0.1)(c1)
    c1 = Conv3D(16, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c1)
    p1 = MaxPooling3D((2, 2, 2))(c1)
    
    c2 = Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(p1)
    c2 = Dropout(0.1)(c2)
    c2 = Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c2)
    p2 = MaxPooling3D((2, 2, 2))(c2)
     
    c3 = Conv3D(64, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(p2)
    c3 = Dropout(0.2)(c3)
    c3 = Conv3D(64, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c3)
    p3 = MaxPooling3D((2, 2, 2))(c3)
     
    c4 = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(p3)
    c4 = Dropout(0.2)(c4)
    c4 = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c4)
    p4 = MaxPooling3D(pool_size=(2, 2, 2))(c4)
     
    c5 = Conv3D(256, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(p4)
    c5 = Dropout(0.3)(c5)
    c5 = Conv3D(256, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c5)
    
    a1 = Flatten()(c5)
    a1 = concatenate([a1,age_m])
    a1 = BatchNormalization()(a1)
    
    a1 = Dense(128,activation = 'relu')(a1)
    a1 = Dense(64,activation = 'relu')(a1)
    outputs = Dense(1,activation = 'sigmoid')(a1)
    
    model = Model(inputs = [input_img,age_m] , outputs = outputs)
    
    return model



def ImageDataLoader_survival( image_list,data, batch_size):

    L = len(image_list)
    print(image_list)
    #keras needs the generator infinite, so we will use while true  
    while True:

        batch_start = 0
        batch_end = batch_size
        

        while batch_start < L:
            limit = min(batch_end, L)
            
            X, age, Y = [], [], []
            X.append(load_img(image_list[batch_start:limit]))
            age.append(data['Age'].iloc[batch_start:limit])
            Y.append(data['Survival_days'].iloc[batch_start:limit])

            yield (np.array(X[0]),np.array(age[0])), (np.array(Y[0])) #a tuple with two numpy arrays with batch_size samples     
            batch_start += batch_size   
            batch_end   += batch_size 
